{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade tabula-py\n",
        "#!pip install camelot-py[pdf] pandas openpyxl\n",
        "#!pip install pillow\n",
        "#!pip install pdf2image\n",
        "#!pip install Spire.PDF\n",
        "!apt-get install poppler-utils\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wF06gPNf6PI",
        "outputId": "7a276698-7ed2-4a1b-c329-e6929784cae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.4 [186 kB]\n",
            "Fetched 186 kB in 1s (212 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 121918 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.4) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.4) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Text_Extraction"
      ],
      "metadata": {
        "id": "4kYsIB7If8LY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxvYsOnBcWzq",
        "outputId": "56954627-4ace-4bbb-ca97-1476194e77c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting camelot-py[cv]\n",
            "  Downloading camelot_py-0.11.0-py3-none-any.whl (40 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: chardet>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from camelot-py[cv]) (5.2.0)\n",
            "Requirement already satisfied: click>=6.7 in /usr/local/lib/python3.10/dist-packages (from camelot-py[cv]) (8.1.7)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from camelot-py[cv]) (1.25.2)\n",
            "Requirement already satisfied: openpyxl>=2.5.8 in /usr/local/lib/python3.10/dist-packages (from camelot-py[cv]) (3.1.3)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.10/dist-packages (from camelot-py[cv]) (2.0.3)\n",
            "Requirement already satisfied: pdfminer.six>=20200726 in /usr/local/lib/python3.10/dist-packages (from camelot-py[cv]) (20231228)\n",
            "Collecting pypdf>=3.0.0 (from camelot-py[cv])\n",
            "  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from camelot-py[cv]) (0.9.0)\n",
            "Collecting ghostscript>=0.7 (from camelot-py[cv])\n",
            "  Downloading ghostscript-0.7-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: opencv-python>=3.4.2.17 in /usr/local/lib/python3.10/dist-packages (from camelot-py[cv]) (4.8.0.76)\n",
            "INFO: pip is looking at multiple versions of camelot-py[cv] to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting camelot-py[cv]\n",
            "  Downloading camelot_py-0.10.1-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyPDF2>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from camelot-py[cv]) (3.0.1)\n",
            "  Downloading camelot_py-0.10.0-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading camelot_py-0.9.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl>=2.5.8->camelot-py[cv]) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->camelot-py[cv]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->camelot-py[cv]) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->camelot-py[cv]) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six>=20200726->camelot-py[cv]) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six>=20200726->camelot-py[cv]) (42.0.7)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six>=20200726->camelot-py[cv]) (1.16.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=0.23.4->camelot-py[cv]) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six>=20200726->camelot-py[cv]) (2.22)\n",
            "Installing collected packages: camelot-py\n",
            "Successfully installed camelot-py-0.9.0\n"
          ]
        }
      ],
      "source": [
        "#!pip install pymupdf pdfminer.six pypdf2 pdfplumber python-docx\n",
        "!pip install camelot-py[cv]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "from docx import Document\n",
        "\n",
        "def clean_text(text):\n",
        "    return ''.join(c for c in text if ord(c) in range(32, 127) or ord(c) in [9, 10, 13])\n",
        "\n",
        "def extract_text_pymupdf(pdf_path, output_docx):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    document = Document()\n",
        "\n",
        "    for page_num in range(len(doc)):\n",
        "        page = doc.load_page(page_num)\n",
        "        text = page.get_text(\"text\")\n",
        "        clean_txt = clean_text(text)\n",
        "        document.add_heading(f\"Page {page_num + 1}\", level=1)\n",
        "        document.add_paragraph(clean_txt)\n",
        "\n",
        "    document.save(output_docx)\n",
        "\n",
        "pdf_path = \"/content/amc-annual-report---2019---20.pdf\"\n",
        "output_docx = \"PyMuPDF_with_text.docx\"\n",
        "extract_text_pymupdf(pdf_path, output_docx)"
      ],
      "metadata": {
        "id": "XN3wwKAicxi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pdfminer.high_level import extract_text\n",
        "from docx import Document\n",
        "\n",
        "def clean_text(text):\n",
        "    return ''.join(c for c in text if ord(c) in range(32, 127) or ord(c) in [9, 10, 13])\n",
        "\n",
        "def extract_text_pdfminer(pdf_path, output_docx):\n",
        "    text = extract_text(pdf_path)\n",
        "    clean_txt = clean_text(text)\n",
        "    document = Document()\n",
        "    document.add_paragraph(clean_txt)\n",
        "    document.save(output_docx)\n",
        "\n",
        "pdf_path = \"/content/amc-annual-report---2019---20.pdf\"\n",
        "output_docx = \"PDFMiner_with_text.docx\"\n",
        "extract_text_pdfminer(pdf_path, output_docx)"
      ],
      "metadata": {
        "id": "u2WOFepDeQLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "from docx import Document\n",
        "\n",
        "def clean_text(text):\n",
        "    return ''.join(c for c in text if ord(c) in range(32, 127) or ord(c) in [9, 10, 13])\n",
        "\n",
        "def extract_text_pypdf2(pdf_path, output_docx):\n",
        "    document = Document()\n",
        "    with open(pdf_path, \"rb\") as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        for page_num in range(len(reader.pages)):\n",
        "            page = reader.pages[page_num]\n",
        "            text = page.extract_text()\n",
        "            clean_txt = clean_text(text)\n",
        "            document.add_heading(f\"Page {page_num + 1}\", level=1)\n",
        "            document.add_paragraph(clean_txt)\n",
        "\n",
        "    document.save(output_docx)\n",
        "\n",
        "pdf_path = \"/content/amc-annual-report---2019---20.pdf\"\n",
        "output_docx = \"PyPDF2_with_text.docx\"\n",
        "extract_text_pypdf2(pdf_path, output_docx)"
      ],
      "metadata": {
        "id": "lu1BmQHIef9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fK2K06tdfzpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "from docx import Document\n",
        "\n",
        "def clean_text(text):\n",
        "    return ''.join(c for c in text if ord(c) in range(32, 127) or ord(c) in [9, 10, 13])\n",
        "\n",
        "def extract_text_pdfplumber(pdf_path, output_docx):\n",
        "    document = Document()\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page_num, page in enumerate(pdf.pages):\n",
        "            text = page.extract_text()\n",
        "            clean_txt = clean_text(text)\n",
        "            document.add_heading(f\"Page {page_num + 1}\", level=1)\n",
        "            document.add_paragraph(clean_txt)\n",
        "\n",
        "    document.save(output_docx)\n",
        "\n",
        "pdf_path = \"/content/amc-annual-report---2019---20.pdf\"\n",
        "output_docx = \"pdfplumber_with_text.docx\"\n",
        "extract_text_pdfplumber(pdf_path, output_docx)"
      ],
      "metadata": {
        "id": "nGRQPyzle5o1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Table_Extraction"
      ],
      "metadata": {
        "id": "7JdbRObVgD6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "from docx import Document\n",
        "\n",
        "def extract_tables_pdfplumber(pdf_path):\n",
        "    tables = []\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            extracted_tables = page.extract_tables()\n",
        "            if extracted_tables:\n",
        "                tables.extend(extracted_tables)\n",
        "    return tables\n",
        "\n",
        "def save_tables_to_word(tables, output_docx):\n",
        "    doc = Document()\n",
        "    for i, table in enumerate(tables):\n",
        "        if table:  # Check if the table is not empty\n",
        "            table_doc = doc.add_table(rows=len(table), cols=len(table[0]))\n",
        "            for row_idx, row in enumerate(table):\n",
        "                for col_idx, cell in enumerate(row):\n",
        "                    table_doc.cell(row_idx, col_idx).text = str(cell)  # Ensure cell content is string\n",
        "            doc.add_paragraph(\"\\n\")  # Add a new line between tables\n",
        "    doc.save(output_docx)\n",
        "\n",
        "# Example usage\n",
        "pdf_path = \"/content/amc-annual-report---2020---21.pdf\"\n",
        "tables = extract_tables_pdfplumber(pdf_path)\n",
        "output_docx = \"pdfplumber_tables_extracted.docx\"\n",
        "save_tables_to_word(tables, output_docx)\n"
      ],
      "metadata": {
        "id": "paS0_YoTY4Bq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from docx import Document\n",
        "from docx.shared import Inches\n",
        "\n",
        "def save_tables_to_word(tables, output_docx, output_folder):\n",
        "    if not tables:\n",
        "        print(\"No tables found in the PDF.\")\n",
        "        return\n",
        "\n",
        "    # Create the output folder if it doesn't exist\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    doc = Document()\n",
        "\n",
        "    # Add each table to the Word document\n",
        "    for index, table in enumerate(tables):\n",
        "        table_filename = os.path.join(output_folder, f\"table_{index + 1}.png\")\n",
        "\n",
        "        if table.empty:\n",
        "            print(f\"Skipping empty table {index + 1}\")\n",
        "            continue\n",
        "\n",
        "        # Convert the table to an image using matplotlib\n",
        "        plt.figure(figsize=(10, 6))  # Adjust size as needed\n",
        "        ax = plt.subplot(111, frame_on=False)\n",
        "        ax.xaxis.set_visible(False)\n",
        "        ax.yaxis.set_visible(False)\n",
        "        plt.table(cellText=table.values, colLabels=table.columns, loc='center')\n",
        "        plt.savefig(table_filename, bbox_inches='tight', pad_inches=0)\n",
        "        plt.close()\n",
        "\n",
        "        # Insert the image into the Word document\n",
        "        doc.add_picture(table_filename, width=Inches(5))  # Adjust width as needed\n",
        "        doc.add_paragraph()  # Add space between tables\n",
        "\n",
        "    # Save the Word document\n",
        "    doc.save(output_docx)\n",
        "\n",
        "# Example usage\n",
        "pdf_path = \"/content/amc-annual-report---2020---21.pdf\"\n",
        "tables = extract_tables_tabula(pdf_path)\n",
        "output_docx = \"tables_from_pdf.docx\"\n",
        "output_folder = \"table_images_matplotlib\"\n",
        "save_tables_to_word(tables, output_docx, output_folder)\n"
      ],
      "metadata": {
        "id": "1_dVJGj1lLGw",
        "outputId": "9ef86707-1b57-413b-8aaa-7bd957d23835",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tabula.backend:Got stderr: Jun 06, 2024 12:50:24 PM org.apache.pdfbox.pdmodel.graphics.color.PDICCBased ensureDisplayProfile\n",
            "WARNING: ICC profile is Perceptual, ignoring, treating as Display class\n",
            "Jun 06, 2024 12:50:26 PM org.apache.pdfbox.pdmodel.graphics.color.PDICCBased ensureDisplayProfile\n",
            "WARNING: ICC profile is Perceptual, ignoring, treating as Display class\n",
            "Jun 06, 2024 12:50:29 PM org.apache.pdfbox.pdmodel.graphics.color.PDICCBased ensureDisplayProfile\n",
            "WARNING: ICC profile is Perceptual, ignoring, treating as Display class\n",
            "Jun 06, 2024 12:51:14 PM org.apache.pdfbox.pdmodel.graphics.color.PDICCBased ensureDisplayProfile\n",
            "WARNING: ICC profile is Perceptual, ignoring, treating as Display class\n",
            "\n",
            ") missing from current font.\n",
            "  plt.savefig(table_filename, bbox_inches='tight', pad_inches=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping empty table 9\n",
            "Skipping empty table 25\n",
            "Skipping empty table 31\n",
            "Skipping empty table 47\n",
            "Skipping empty table 50\n",
            "Skipping empty table 52\n",
            "Skipping empty table 53\n",
            "Skipping empty table 55\n",
            "Skipping empty table 65\n",
            "Skipping empty table 69\n",
            "Skipping empty table 70\n",
            "Skipping empty table 73\n",
            "Skipping empty table 74\n",
            "Skipping empty table 78\n",
            "Skipping empty table 79\n",
            "Skipping empty table 82\n",
            "Skipping empty table 86\n",
            "Skipping empty table 91\n",
            "Skipping empty table 92\n",
            "Skipping empty table 94\n",
            "Skipping empty table 96\n",
            "Skipping empty table 99\n",
            "Skipping empty table 104\n",
            "Skipping empty table 109\n",
            "Skipping empty table 110\n",
            "Skipping empty table 113\n",
            "Skipping empty table 117\n",
            "Skipping empty table 120\n",
            "Skipping empty table 121\n",
            "Skipping empty table 123\n",
            "Skipping empty table 124\n",
            "Skipping empty table 128\n",
            "Skipping empty table 135\n",
            "Skipping empty table 138\n",
            "Skipping empty table 151\n",
            "Skipping empty table 155\n",
            "Skipping empty table 156\n",
            "Skipping empty table 159\n",
            "Skipping empty table 165\n",
            "Skipping empty table 170\n",
            "Skipping empty table 171\n",
            "Skipping empty table 173\n",
            "Skipping empty table 174\n",
            "Skipping empty table 177\n",
            "Skipping empty table 178\n",
            "Skipping empty table 181\n",
            "Skipping empty table 186\n",
            "Skipping empty table 191\n",
            "Skipping empty table 194\n",
            "Skipping empty table 197\n",
            "Skipping empty table 205\n",
            "Skipping empty table 208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#image extractiion"
      ],
      "metadata": {
        "id": "LEBULiewE9fu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YQ4mgUNJiDIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "from PIL import Image\n",
        "from docx import Document\n",
        "from docx.shared import Inches\n",
        "import fitz\n",
        "\n",
        "def extract_images_pymupdf(pdf_path):\n",
        "    images = []\n",
        "    doc = fitz.open(pdf_path)\n",
        "    for page_number in range(len(doc)):\n",
        "        page = doc.load_page(page_number)\n",
        "        image_list = page.get_images(full=True)\n",
        "        for img_index, img_info in enumerate(image_list):\n",
        "            xref = img_info[0]\n",
        "            base_image = doc.extract_image(xref)\n",
        "            image_bytes = base_image[\"image\"]\n",
        "            image = Image.open(io.BytesIO(image_bytes))\n",
        "            images.append(image)\n",
        "    return images\n",
        "\n",
        "def save_images_to_word(images, output_docx):\n",
        "    doc = Document()\n",
        "    doc.add_heading('Images extracted with PyMuPDF', level=1)\n",
        "    for i, image in enumerate(images):\n",
        "        # Convert the image to RGB mode to avoid the 'read' attribute error\n",
        "        image = image.convert(\"RGB\")\n",
        "        # Add the image to the document\n",
        "        img_io = io.BytesIO()\n",
        "        image.save(img_io, format='JPEG')\n",
        "        img_io.seek(0)\n",
        "        doc.add_picture(img_io, width=Inches(5))\n",
        "        doc.add_paragraph(f'Image {i+1}')\n",
        "    doc.save(output_docx)\n",
        "\n",
        "# Example usage\n",
        "pdf_path = \"/content/amc-annual-report---2020---21.pdf\"\n",
        "images_pymupdf = extract_images_pymupdf(pdf_path)\n",
        "output_docx_pymupdf = \"images_pymupdf.docx\"\n",
        "save_images_to_word(images_pymupdf, output_docx_pymupdf)\n"
      ],
      "metadata": {
        "id": "uG2ldAZmGX-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pdf2image import convert_from_path\n",
        "import os\n",
        "\n",
        "# Path to the PDF file\n",
        "pdf_path = '/content/amc-annual-report---2020---21.pdf'\n",
        "\n",
        "# Directory to save extracted images\n",
        "output_folder = '/content/pdf2image_extraction'\n",
        "\n",
        "# Create the output folder if it doesn't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Extract images from the PDF\n",
        "images = convert_from_path(pdf_path)\n",
        "\n",
        "# Save the extracted images\n",
        "for i, image in enumerate(images):\n",
        "    image_path = os.path.join(output_folder, f'Image_{i}.png')\n",
        "    image.save(image_path, 'PNG')"
      ],
      "metadata": {
        "id": "DUMEgAgWSgGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Create a directory to save images if it doesn't exist\n",
        "os.makedirs('pdf2image_extraction', exist_ok=True)"
      ],
      "metadata": {
        "id": "fsxLPeRpUnGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r pdf2image_extraction.zip pdf2image_extraction/"
      ],
      "metadata": {
        "id": "yWQEl3yhohVo",
        "outputId": "ef7f556a-fa42-4f96-9bdd-32e47ab96263",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: pdf2image_extraction/ (stored 0%)\n",
            "  adding: pdf2image_extraction/Image_98.png (deflated 9%)\n",
            "  adding: pdf2image_extraction/Image_14.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_116.png (deflated 9%)\n",
            "  adding: pdf2image_extraction/Image_83.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_21.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_55.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_103.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_10.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_5.png (deflated 13%)\n",
            "  adding: pdf2image_extraction/Image_118.png (deflated 9%)\n",
            "  adding: pdf2image_extraction/Image_6.png (deflated 6%)\n",
            "  adding: pdf2image_extraction/Image_140.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_40.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_77.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_95.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_119.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_85.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_147.png (deflated 4%)\n",
            "  adding: pdf2image_extraction/Image_47.png (deflated 9%)\n",
            "  adding: pdf2image_extraction/Image_18.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_148.png (deflated 23%)\n",
            "  adding: pdf2image_extraction/Image_82.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_33.png (deflated 11%)\n",
            "  adding: pdf2image_extraction/Image_122.png (deflated 6%)\n",
            "  adding: pdf2image_extraction/Image_130.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_25.png (deflated 9%)\n",
            "  adding: pdf2image_extraction/Image_4.png (deflated 12%)\n",
            "  adding: pdf2image_extraction/Image_42.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_53.png (deflated 9%)\n",
            "  adding: pdf2image_extraction/Image_67.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_109.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_64.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_104.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_68.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_20.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_125.png (deflated 9%)\n",
            "  adding: pdf2image_extraction/Image_145.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_113.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_51.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_75.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_2.png (deflated 14%)\n",
            "  adding: pdf2image_extraction/Image_126.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_54.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_146.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_137.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_139.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_110.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_86.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_19.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_108.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_106.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_101.png (deflated 6%)\n",
            "  adding: pdf2image_extraction/Image_92.png (deflated 9%)\n",
            "  adding: pdf2image_extraction/Image_50.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_80.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_46.png (deflated 11%)\n",
            "  adding: pdf2image_extraction/Image_76.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_127.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_32.png (deflated 13%)\n",
            "  adding: pdf2image_extraction/Image_58.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_27.png (deflated 6%)\n",
            "  adding: pdf2image_extraction/Image_23.png (deflated 6%)\n",
            "  adding: pdf2image_extraction/Image_15.png (deflated 6%)\n",
            "  adding: pdf2image_extraction/Image_143.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_35.png (deflated 11%)\n",
            "  adding: pdf2image_extraction/Image_66.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_102.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_22.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_81.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_56.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_107.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_144.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_138.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_7.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_73.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_120.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_94.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_16.png (deflated 6%)\n",
            "  adding: pdf2image_extraction/Image_128.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_99.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_78.png (deflated 6%)\n",
            "  adding: pdf2image_extraction/Image_29.png (deflated 12%)\n",
            "  adding: pdf2image_extraction/Image_12.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_26.png (deflated 12%)\n",
            "  adding: pdf2image_extraction/Image_132.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_135.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_100.png (deflated 6%)\n",
            "  adding: pdf2image_extraction/Image_142.png (deflated 9%)\n",
            "  adding: pdf2image_extraction/Image_133.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_72.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_9.png (deflated 6%)\n",
            "  adding: pdf2image_extraction/Image_38.png (deflated 9%)\n",
            "  adding: pdf2image_extraction/Image_105.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_74.png (deflated 9%)\n",
            "  adding: pdf2image_extraction/Image_124.png (deflated 9%)\n",
            "  adding: pdf2image_extraction/Image_97.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_34.png (deflated 6%)\n",
            "  adding: pdf2image_extraction/Image_11.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_123.png (deflated 9%)\n",
            "  adding: pdf2image_extraction/Image_88.png (deflated 9%)\n",
            "  adding: pdf2image_extraction/Image_0.png (deflated 0%)\n",
            "  adding: pdf2image_extraction/Image_114.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_44.png (deflated 10%)\n",
            "  adding: pdf2image_extraction/Image_121.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_141.png (deflated 9%)\n",
            "  adding: pdf2image_extraction/Image_91.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_48.png (deflated 6%)\n",
            "  adding: pdf2image_extraction/Image_24.png (deflated 9%)\n",
            "  adding: pdf2image_extraction/Image_8.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_89.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_134.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_36.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_41.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_131.png (deflated 6%)\n",
            "  adding: pdf2image_extraction/Image_1.png (deflated 3%)\n",
            "  adding: pdf2image_extraction/Image_136.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_31.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_30.png (deflated 9%)\n",
            "  adding: pdf2image_extraction/Image_52.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_84.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_79.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_70.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_45.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_117.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_60.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_49.png (deflated 6%)\n",
            "  adding: pdf2image_extraction/Image_112.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_39.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_28.png (deflated 9%)\n",
            "  adding: pdf2image_extraction/Image_57.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_17.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_63.png (deflated 9%)\n",
            "  adding: pdf2image_extraction/Image_115.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_129.png (deflated 6%)\n",
            "  adding: pdf2image_extraction/Image_93.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_61.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_71.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_43.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_3.png (deflated 6%)\n",
            "  adding: pdf2image_extraction/Image_96.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_65.png (deflated 10%)\n",
            "  adding: pdf2image_extraction/Image_62.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_59.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_111.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_37.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_13.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_90.png (deflated 8%)\n",
            "  adding: pdf2image_extraction/Image_87.png (deflated 7%)\n",
            "  adding: pdf2image_extraction/Image_69.png (deflated 6%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the zip file\n",
        "files.download('pdf2image_extraction.zip')"
      ],
      "metadata": {
        "id": "8sbwsU66onWF",
        "outputId": "2b31cbd5-9112-47b8-8b2b-1388dec87e83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f7b30d2f-8ae5-4124-b18a-0a717a1e7923\", \"pdf2image_extraction.zip\", 58251504)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}